{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Large XML into entry based single files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import json as json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from parser.splited_xml_parser import SplitedEntryParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entry_dict(entry):\n",
    "    # Get the entry dictionary\n",
    "    UEP = SplitedEntryParser(entry)\n",
    "    \n",
    "\n",
    "    entry_dict = {'accession': UEP.get_accession(),\\\n",
    "                   'name': UEP.get_name(),\\\n",
    "                    'gene': UEP.get_gene(),\\\n",
    "                    'organism': UEP.get_organism(),\\\n",
    "                    'sequence': UEP.get_sequence(),\\\n",
    "                    'uniprotId': UEP.get_uniprotId(),\\\n",
    "                    'ptm': UEP.get_ptm(),\\\n",
    "                    'references': UEP.get_references()}\n",
    "    \n",
    "    return entry_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xml(filename, split=True, parse=False):\n",
    "    context = ET.iterparse(filename, events=(\"start\", \"end\"))\n",
    "    event, root = next(context)  # Get root element of the XML file\n",
    "\n",
    "    entry_count = 0\n",
    "    for event, elem in context:\n",
    "        if event == \"end\" and elem.tag == \"{http://uniprot.org/uniprot}entry\":  \n",
    "            entry_count += 1\n",
    "\n",
    "            if split==True:\n",
    "                # Write each entry to a separate XML file\n",
    "                with open(f\"xmldataset/entry_{entry_count}.xml\", \"wb\") as f:  \n",
    "                    f.write(ET.tostring(elem, encoding=\"utf-8\"))\n",
    "\n",
    "\n",
    "            # set parse == False if planing to parallelize\n",
    "            if parse==True:\n",
    "                # Write each entry to a separate JSON file\n",
    "                data = get_entry_dict(elem)  # Get a dictionary of the entry data\n",
    "                with open(f\"jsondataset/entry_{entry_count}.json\", \"w\") as f:  \n",
    "                    json.dump(data, f)\n",
    "\n",
    "            # print the progress\n",
    "            if entry_count % 1000 == 0:\n",
    "                print(f\"{entry_count} entries processed\")\n",
    "            \n",
    "            # print tqdm progressbar\n",
    "            # tqdm.write(f\"{entry_count} entries processed\")\n",
    "\n",
    "            # Clear the element to free memory\n",
    "            root.clear()  # Discard the element data to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_xml(\"largedata/whole uniprot.xml\", split=True, parse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGH Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ptm-position'] = df['ptm'].apply(lambda x: [item['Position'] for item in x] if x is not None else None)\n",
    "df['ptm-description'] = df['ptm'].apply(lambda x: [item['Description'] for item in x] if x is not None else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Open the XML file\n",
    "with open('P12235.xml', 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Parse the XML file\n",
    "soup = BeautifulSoup(data, 'xml')\n",
    "\n",
    "# Find all modified residues\n",
    "modified_residues = soup.find_all('feature', {'type': 'modified residue'})\n",
    "\n",
    "# Get a dictionary of all evidences with their associated references\n",
    "evidences = {evidence.get('key'): evidence for evidence in soup.find_all('evidence')}\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Iterate over all modified residues\n",
    "for residue in modified_residues:\n",
    "    position = residue.location.begin.get('position')\n",
    "    description = residue.get('description')\n",
    "\n",
    "    # Get the evidence IDs for this residue\n",
    "    evidence_ids = residue.get('evidence').split()\n",
    "\n",
    "    # Get the corresponding references for each evidence\n",
    "    references = []\n",
    "    for evidence_id in evidence_ids:\n",
    "        evidence = evidences.get(evidence_id)\n",
    "        if evidence:\n",
    "            reference_key = evidence.get('key')\n",
    "            references.append(reference_key)\n",
    "    \n",
    "    data.append({\n",
    "        'Position': position, \n",
    "        'Description': description, \n",
    "        'Evidence': references\n",
    "    })\n",
    "\n",
    "# Now, 'data' is a list of dictionaries, each containing the position, description, and evidence for a modified residue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "input = gzip.open('all ptm types_AAC.xml.gz', 'r')\n",
    "tree = ET.parse(input)\n",
    "root = tree.getroot()\n",
    "\n",
    "ns = {'uniprot': 'http://uniprot.org/uniprot'}  # Namespace\n",
    "\n",
    "# Iterate through each entry\n",
    "for entry in root.findall('uniprot:entry', ns):\n",
    "    ptm_evidence_map = {}  # Mapping of PTMs to their references\n",
    "\n",
    "    # Get all references in the entry\n",
    "    references = {ref.get('key'): ref for ref in entry.findall('uniprot:reference', ns)}\n",
    "\n",
    "    # Get all evidences in the entry\n",
    "    evidences = {evidence.get('key'): evidence for evidence in entry.findall('uniprot:evidence', ns)} \n",
    "\n",
    "    # Get all PTMs in the entry\n",
    "    ptms = [feature for feature in entry.findall('uniprot:feature', ns) if feature.get('type') == 'modified residue']\n",
    "\n",
    "    # For each PTM, find its evidence and then its reference\n",
    "    for ptm in ptms:\n",
    "        evidence_key = ptm.get('evidence')\n",
    "        if evidence_key:\n",
    "            evidence = evidences.get(evidence_key)\n",
    "            if evidence:\n",
    "                reference_key = evidence.get('source')\n",
    "                if reference_key:\n",
    "                    reference = references.get(reference_key)\n",
    "                    if reference:\n",
    "                        # Add to the mapping\n",
    "                        ptm_description = ptm.get('description')\n",
    "                        ptm_evidence_map[ptm_description] = reference\n",
    "                        \n",
    "\n",
    "    # Print the mapping\n",
    "    for ptm, reference in ptm_evidence_map.items():\n",
    "        print(f'PTM: {ptm}')\n",
    "        print(f'Reference: {ET.tostring(reference, encoding=\"unicode\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_references(self):\n",
    "    self.references = {}\n",
    "    for ref in self.entry.findall(self.ns+'reference'):\n",
    "        key = ref.get('key')\n",
    "        pubmed_id = ref.find(\".//{%s}dbReference[@type='PubMed']\" % self.ns)\n",
    "        if pubmed_id is not None:\n",
    "            self.references[key] = pubmed_id.get('id')\n",
    "\n",
    "def get_evidences(self):\n",
    "    self.ptms = []\n",
    "    for ptm in self.entry.findall(\".//{%s}feature[@type='modified residue']\" % self.ns):\n",
    "        description = ptm.find(\"{%s}description\" % self.ns).text\n",
    "        position = ptm.find(\".//{%s}position\" % self.ns).get('position')\n",
    "        evidence = ptm.get('evidence').split(' ')\n",
    "        pubmed_ids = [self.references.get(e) for e in evidence]\n",
    "        self.ptms.append({'description': description, 'position': position, 'pubmed_ids': pubmed_ids})\n",
    "\n",
    "def parse_entry(self, entry):\n",
    "    self.entry = entry\n",
    "    self.get_references()\n",
    "    self.get_evidences()\n",
    "    return self.ptms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "references = []\n",
    "ns = {'uniprot': 'http://uniprot.org/uniprot'}\n",
    "for i, entry in enumerate(root.findall('{http://uniprot.org/uniprot}entry')):\n",
    "        print(i,\"-----------------------------------\")\n",
    "        for ref in entry.findall('uniprot:reference', ns):\n",
    "                        reference = {}\n",
    "                        key = ref.get('key')\n",
    "                        reference['key'] = key\n",
    "                        citation_type = ref.find('uniprot:citation', ns).get('type')\n",
    "                        reference[\"citation_type\"] = citation_type\n",
    "\n",
    "                        #print(i, key, citation_type, ref)\n",
    "                        if citation_type == 'journal article':\n",
    "                                try:\n",
    "                                        reference['journal'] = ref.find('uniprot:citation', ns).get('name')\n",
    "                                except:\n",
    "                                        reference['journal'] = None\n",
    "                                try:\n",
    "                                        reference['date'] = ref.find('uniprot:citation', ns).get('date')\n",
    "                                except:\n",
    "                                        reference['date'] = None\n",
    "                                try:\n",
    "                                        reference['title'] = ref.find('uniprot:citation/uniprot:title', ns).text\n",
    "                                except:\n",
    "                                        reference['title'] = None\n",
    "                                try:\n",
    "                                        reference['authors'] = [author.get('name') for author in ref.findall('uniprot:citation/uniprot:authorList/uniprot:person', ns)]\n",
    "                                except:\n",
    "                                        reference['authors'] = None\n",
    "                                try:\n",
    "                                        reference['pubmedId'] = ref.find('uniprot:citation/uniprot:dbReference[@type=\"PubMed\"]', ns).get('id')\n",
    "                                except:\n",
    "                                        reference['pubmedId'] = None\n",
    "                                try:\n",
    "                                        reference['doi'] = ref.find('uniprot:citation/uniprot:dbReference[@type=\"DOI\"]', ns).get('id')\n",
    "                                except:\n",
    "                                        reference['doi'] = None\n",
    "                        if citation_type == 'submission':  \n",
    "                                try: \n",
    "                                        reference['db'] = ref.find('uniprot:citation', ns).get('db')\n",
    "                                except:\n",
    "                                        reference['db'] = None\n",
    "                                try:\n",
    "                                        reference['date'] = ref.find('uniprot:citation', ns).get('date')\n",
    "                                except:\n",
    "                                        reference['date'] = None\n",
    "                                try:\n",
    "                                        reference['scope'] = [scope.text for scope in ref.findall('uniprot:scope', ns)]\n",
    "                                except:\n",
    "                                        reference['scope'] = None\n",
    "                                try:\n",
    "                                        reference['source'] = [source.text for source in ref.findall('uniprot:source', ns)]\n",
    "                                except:\n",
    "                                        reference['source'] = None\n",
    "\n",
    "                        references.append(reference)\n",
    "                        print(reference)\n",
    "                        print(\"---------------------------------------------------\")\n",
    "       \n",
    "                     \n",
    "\n",
    "#print(references )           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
