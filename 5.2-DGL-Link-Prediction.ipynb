{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7bf9ad",
   "metadata": {},
   "source": [
    "## HGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879fd325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f21ce8",
   "metadata": {},
   "source": [
    "### Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e16e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(uri = \"bolt://localhost:7687\",\\\n",
    "                              auth = (\"neo4j\",\"12341234\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a1864",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eccbcb8",
   "metadata": {},
   "source": [
    "### Link Prediction (Data Preperation)\n",
    "\n",
    "- I have the following nodes in Neo4j: Compound.\n",
    "Modified_residue, Organism, PTM_Type, Pathway, Protein, Reference. \n",
    "- Following are the relationships: (Protein, Pathways), (Protein, PTM_types),(PTM_Types, Modified_residue),(Modified_residue, reference),(Pathway, Compound). Help me with the following \n",
    "\n",
    "- (1) Extract a heterogeneous graph from neo4j  and save it as CSV file \n",
    "- (2) Use a CSV file to create a DGL heterogeneous graph, \n",
    "\n",
    "next I am asking you to create a graph neural network on this heterogeneous graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6cbaf5",
   "metadata": {},
   "source": [
    "![img](schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718fe595",
   "metadata": {},
   "source": [
    "### Get Node Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85922760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find  unique nodes\n",
    "def getnode(query):\n",
    "    res = []\n",
    "    with driver.session() as session:\n",
    "        info = session.run(query)\n",
    "        for item in info:\n",
    "            res.append({\"source\":item.values()[0]})\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_query = \"MATCH (p:Protein) RETURN p.UID AS source\"\n",
    "protein_df=getnode(protein_query)\n",
    "p2index = {p:i for i,p in enumerate(protein_df[\"source\"].unique())}\n",
    "with open(\"hgt_data/p2index.json\",\"w\") as f:\n",
    "    json.dump(p2index,f)\n",
    "\n",
    "pathway_query = \"MATCH (p:Pathway) RETURN p.PWID AS source\"\n",
    "pathway_df=getnode(pathway_query)\n",
    "pw2index = {p:i for i,p in enumerate(pathway_df[\"source\"].unique())}\n",
    "with open(\"hgt_data/pw2index.json\",\"w\") as f:\n",
    "    json.dump(pw2index,f)\n",
    "\n",
    "modified_residue_query = \"MATCH (p:Modified_residue) RETURN p.MRID AS source\"\n",
    "modified_residue_df=getnode(modified_residue_query)\n",
    "mr2index = {p:i for i,p in enumerate(modified_residue_df[\"source\"].unique())}\n",
    "with open(\"hgt_data/mr2index.json\",\"w\") as f:\n",
    "    json.dump(mr2index,f)\n",
    "\n",
    "PTM_query = \"MATCH (p:PTM_Type) RETURN p.PTMID AS source\"\n",
    "PTM_df=getnode(PTM_query)\n",
    "ptm2index = {p:i for i,p in enumerate(PTM_df[\"source\"].unique())}\n",
    "with open(\"hgt_data/ptm2index.json\",\"w\") as f:\n",
    "    json.dump(ptm2index,f)\n",
    "\n",
    "organism_query = \"MATCH (p:Organism) RETURN p.name AS source\"\n",
    "organism_df=getnode(organism_query)\n",
    "org2index = {p:i for i,p in enumerate(organism_df[\"source\"].unique())}\n",
    "with open(\"hgt_data/org2index.json\",\"w\") as f:\n",
    "    json.dump(org2index,f)\n",
    "\n",
    "compound_query = \"MATCH (p:Compound) RETURN p.CID AS source\"\n",
    "compound_df=getnode(compound_query)\n",
    "cpd2index = {p:i for i,p in enumerate(compound_df[\"source\"].unique())}\n",
    "with open(\"hgt_data/cpd2index.json\",\"w\") as f:\n",
    "    json.dump(cpd2index,f)\n",
    "\n",
    "Reference_query = \"MATCH (p:Reference) RETURN p.PMID AS source\"\n",
    "Reference_df=getnode(Reference_query)\n",
    "ref2index = {p:i for i,p in enumerate(Reference_df[\"source\"].unique())}\n",
    "with open(\"hgt_data/ref2index.json\",\"w\") as f:\n",
    "    json.dump(ref2index,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611cb990",
   "metadata": {},
   "source": [
    "### Get Relationship Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f621c7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(query,relation):\n",
    "    res = []\n",
    "    with driver.session() as session:\n",
    "        info = session.run(query)\n",
    "        for item in info:\n",
    "            res.append({\"source\":item.values()[0],\\\n",
    "                        \"target\":item.values()[1],\\\n",
    "                        \"relation\":relation})\n",
    "    return pd.DataFrame(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf0f41",
   "metadata": {},
   "source": [
    "#### Protein to Pathway relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0246c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_pathway_query = \"MATCH (p:Protein)-[r:PARTICIPATES_IN]->(pw:Pathway)\\\n",
    "         RETURN p.UID AS source, pw.PWID AS target\"\n",
    "protein_pathway_df=getdata(protein_pathway_query,\"PARTICIPATES_IN\")\n",
    "\n",
    "protein_pathway_df['source_index'] = protein_pathway_df['source'].apply(lambda x:p2index[x])\n",
    "protein_pathway_df['target_index'] = protein_pathway_df['target'].apply(lambda x:pw2index[x])\n",
    "\n",
    "protein_pathway_df.to_csv(\"hgt_data/protein_pathway.csv\",index=False)\n",
    "protein_pathway_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_pathway_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0faf4",
   "metadata": {},
   "source": [
    "#### Protein to Modified_residue relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "protein_modified_residue_query = \"MATCH (p:Protein)-[r:HAS_MODIFIED_RESIDUE]->(mr:Modified_residue)\\\n",
    "         RETURN p.UID AS source, mr.MRID AS target\"\n",
    "protein_modified_residue_df=getdata(protein_modified_residue_query,\"HAS_MODIFIED_RESIDUE\")\n",
    "\n",
    "protein_modified_residue_df['source_index'] = protein_modified_residue_df['source'].apply(lambda x:p2index[x])\n",
    "protein_modified_residue_df['target_index'] = protein_modified_residue_df['target'].apply(lambda x:mr2index[x])\n",
    "\n",
    "protein_modified_residue_df.to_csv(\"hgt_data/protein_modified_residue.csv\",index=False)\n",
    "protein_modified_residue_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_modified_residue_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7b07d2",
   "metadata": {},
   "source": [
    "#### Modified_residue to PTM_Type relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_residue_ptm_type_query = \"MATCH (mr:Modified_residue)-[r:HAS_PTM_TYPE]->(pt:PTM_Type)\\\n",
    "            RETURN mr.MRID AS source, pt.PTMID AS target\"\n",
    "modified_residue_ptm_type_df=getdata(modified_residue_ptm_type_query,\"HAS_PTM_TYPE\")\n",
    "\n",
    "modified_residue_ptm_type_df['source_index'] = modified_residue_ptm_type_df['source'].apply(lambda x:mr2index[x])\n",
    "modified_residue_ptm_type_df['target_index'] = modified_residue_ptm_type_df['target'].apply(lambda x:ptm2index[x])\n",
    "\n",
    "modified_residue_ptm_type_df.to_csv(\"hgt_data/modified_residue_ptm_type.csv\",index=False)\n",
    "modified_residue_ptm_type_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_residue_ptm_type_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc0710",
   "metadata": {},
   "source": [
    "#### PPI_INTERACTION between two proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c113864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_query = \"MATCH (p1:Protein)-[r:HAS_PPI_INTERACTION]->(p2:Protein)\\\n",
    "            RETURN p1.UID AS source, p2.UID AS target\"\n",
    "ppi_df=getdata(ppi_query,\"HAS_PPI_INTERACTION\")\n",
    "\n",
    "ppi_df['source_index'] = ppi_df['source'].apply(lambda x:p2index[x])\n",
    "ppi_df['target_index'] = ppi_df['target'].apply(lambda x:p2index[x])\n",
    "\n",
    "ppi_df.to_csv(\"hgt_data/ppi.csv\",index=False)\n",
    "ppi_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c4c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d909eb86",
   "metadata": {},
   "source": [
    "#### Modified_residue to Reference relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_residue_reference_query = \"MATCH (mr:Modified_residue)-[r:HAS_REFERENCE]->(ref:Reference)\\\n",
    "            RETURN mr.MRID AS source, ref.PMID AS target\"\n",
    "modified_residue_reference_df=getdata(modified_residue_reference_query,\"HAS_REFERENCE\")\n",
    "\n",
    "#drop nan\n",
    "modified_residue_reference_df = modified_residue_reference_df.dropna()\n",
    "\n",
    "modified_residue_reference_df['source_index'] = modified_residue_reference_df['source'].apply(lambda x:mr2index[x])\n",
    "modified_residue_reference_df['target_index'] = modified_residue_reference_df['target'].apply(lambda x:ref2index[x])\n",
    "\n",
    "modified_residue_reference_df.to_csv(\"hgt_data/modified_residue_reference.csv\",index=False)\n",
    "modified_residue_reference_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_residue_reference_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa56789",
   "metadata": {},
   "source": [
    "#### Compound to Pathway relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949eea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_pathway_query = \"MATCH (c:Compound)-[r:PARTICIPATES_IN]->(pw:Pathway)\\\n",
    "            RETURN c.CID AS source, pw.PWID AS target\"\n",
    "compound_pathway_df=getdata(compound_pathway_query,\"PARTICIPATES_IN\")\n",
    "\n",
    "compound_pathway_df['source_index'] = compound_pathway_df['source'].apply(lambda x:cpd2index[x])\n",
    "compound_pathway_df['target_index'] = compound_pathway_df['target'].apply(lambda x:pw2index[x])\n",
    "\n",
    "compound_pathway_df.to_csv(\"hgt_data/compound_pathway.csv\",index=False)\n",
    "compound_pathway_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374044c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_pathway_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bf564b",
   "metadata": {},
   "source": [
    "#### Protein to Organism relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc370f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_organism_query = \"MATCH (p:Protein)-[r:BELONGS_TO]->(o:Organism)\\\n",
    "            RETURN p.UID AS source, o.name AS target\"\n",
    "protein_organism_df=getdata(protein_organism_query,\"BELONGS_TO\")\n",
    "\n",
    "\n",
    "protein_organism_df['source_index'] = protein_organism_df['source'].apply(lambda x:p2index[x])\n",
    "protein_organism_df['target_index'] = protein_organism_df['target'].apply(lambda x:org2index[x])\n",
    "\n",
    "protein_organism_df.to_csv(\"hgt_data/protein_organism.csv\",index=False)\n",
    "protein_organism_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_organism_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729f6439",
   "metadata": {},
   "source": [
    "## Heterogeneous Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af014b1",
   "metadata": {},
   "source": [
    "Here's a Python snippet to read CSV files and create a DGL heterogeneous graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47de345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from CSV files\n",
    "protein_pathway = pd.read_csv('hgt_data/protein_pathway.csv')\n",
    "protein_modified_residue = pd.read_csv('hgt_data/protein_modified_residue.csv')\n",
    "modified_residue_ptm_type = pd.read_csv('hgt_data/modified_residue_ptm_type.csv')\n",
    "ppi = pd.read_csv('hgt_data/ppi.csv')\n",
    "modified_residue_reference = pd.read_csv('hgt_data/modified_residue_reference.csv')\n",
    "compound_pathway = pd.read_csv('hgt_data/compound_pathway.csv')\n",
    "protein_organism = pd.read_csv('hgt_data/protein_organism.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f73ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DGL Heterogeneous graph\n",
    "g = dgl.heterograph({\n",
    "    ('protein', 'PARTICIPATES_IN', 'pathway'): (protein_pathway['source_index'].values,\\\n",
    "                                                protein_pathway['target_index'].values),\n",
    "    ('protein', 'HAS_MODIFIED_RESIDUE', 'modified_residue'): (protein_modified_residue['source_index'].values,\\\n",
    "                                                              protein_modified_residue['target_index'].values),\n",
    "    ('modified_residue', 'HAS_PTM_TYPE', 'ptm_type'): (modified_residue_ptm_type['source_index'].values,\\\n",
    "                                                       modified_residue_ptm_type['target_index'].values),\n",
    "    ('protein', 'HAS_PPI_INTERACTION', 'protein'): (ppi['source_index'].values,\\\n",
    "                                                    ppi['target_index'].values),\n",
    "    ('modified_residue', 'HAS_REFERENCE', 'reference'): (modified_residue_reference['source_index'].values,\\\n",
    "                                                         modified_residue_reference['target_index'].values),\n",
    "    ('compound', 'PARTICIPATES_IN', 'pathway'): (compound_pathway['source_index'].values,\\\n",
    "                                                 compound_pathway['target_index'].values),\n",
    "    ('protein', 'BELONGS_TO', 'organism'): (protein_organism['source_index'].values,\\\n",
    "                                            protein_organism['target_index'].values)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28631715",
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input features (here randomly initialized)\n",
    "h_dict = {'protein': torch.randn(g.number_of_nodes('protein'), 10),\n",
    "          'pathway': torch.randn(g.number_of_nodes('pathway'), 10),\n",
    "          'ptm_type': torch.randn(g.number_of_nodes('ptm_type'), 10),\n",
    "          'modified_residue': torch.randn(g.number_of_nodes('modified_residue'), 10),\n",
    "          'reference': torch.randn(g.number_of_nodes('reference'), 10),\n",
    "          'organism': torch.randn(g.number_of_nodes('organism'), 10),\n",
    "          'compound': torch.randn(g.number_of_nodes('compound'), 10)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc75399",
   "metadata": {},
   "source": [
    "## Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fccce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.nn as dglnn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the set of nodes and existing edges\n",
    "# all_nodes = set(range(g.number_of_nodes('protein')))\n",
    "# existing_edges = set(g.edges(etype='HAS_MODIFIED_RESIDUE')[0].cpu().numpy())\n",
    "\n",
    "# # Calculate the set of nodes that do not have an edge\n",
    "# non_existing_edges = all_nodes - existing_edges\n",
    "\n",
    "# # Check if we have enough negative samples\n",
    "# if len(non_existing_edges) < 50:\n",
    "#     print(f\"Not enough negative samples, only have {len(non_existing_edges)}\")\n",
    "# else:\n",
    "#     neg_edges = torch.tensor(random.sample(list(non_existing_edges), 50))\n",
    "\n",
    "#     # Your existing code for generating positive samples\n",
    "#     pos_edges = torch.tensor(random.sample(list(existing_edges), 50))\n",
    "\n",
    "#     # Concatenate positive and negative samples and create labels\n",
    "#     train_edges = torch.cat([pos_edges, neg_edges], dim=0)\n",
    "#     train_labels = torch.cat([torch.ones(len(pos_edges)), torch.zeros(len(neg_edges))], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ca053",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_edges = list(zip(*g.edges(etype='HAS_MODIFIED_RESIDUE')))\n",
    "negative_edges = []\n",
    "\n",
    "while len(negative_edges) < len(positive_edges):\n",
    "    u, v = random.randint(0, g.number_of_nodes('protein') - 1),\\\n",
    "          random.randint(0, g.number_of_nodes('protein') - 1)\n",
    "    if (u, v) not in positive_edges and (u, v) not in negative_edges:\n",
    "        negative_edges.append((u, v))\n",
    "\n",
    "train_edges = torch.tensor(positive_edges + negative_edges)\n",
    "train_labels = torch.tensor([1]*len(positive_edges) + [0]*len(negative_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "                        '_'.join(etype): dglnn.GraphConv(in_dim, hidden_dim)\\\n",
    "                         for etype in g.canonical_etypes}, aggregate='mean')\n",
    "        \n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "                        '_'.join(etype): dglnn.GraphConv(hidden_dim, out_dim)\\\n",
    "                         for etype in g.canonical_etypes}, aggregate='mean')\n",
    "        \n",
    "        \n",
    "    def forward(self, g, h_dict):\n",
    "        h_dict = self.conv1(g, h_dict)\n",
    "        h_dict = {k: F.relu(h) for k, h in h_dict.items()}\n",
    "        h_dict = self.conv2(g, h_dict)\n",
    "        return h_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee6e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and optimizer\n",
    "model = SimpleGNN(10, 20, 10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    h_dict = model(g, h_dict)\n",
    "    \n",
    "    # Only take the embeddings for the 'protein' type as an example\n",
    "    protein_embeddings = h_dict['protein']\n",
    "    \n",
    "    # Compute scores using dot-product similarity as an example\n",
    "    edge_embeddings = protein_embeddings[train_edges]\n",
    "    scores = (edge_embeddings[:, 0] * edge_embeddings[:, 1]).sum(dim=1)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = F.binary_cross_entropy_with_logits(scores, train_labels.float())\n",
    "    \n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f1051f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c5a3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
